# 마이크로 세션: 030 — 고급 프롬프트 기법: CoT와 Few-shot

> **세션 ID**: MS-PY101-030  
> **소요 시간**: 20분  
> **난이도**: medium  
> **청크 타입**: narrative  
> **버전**: v2.1 (7섹션 구조)

---

## §1. 개요

> **Day 2 | AM | 세션 030/043**

이전 세션에서 우리는 점진적 개선 기법을 통해 단순한 비밀번호 검사기를 전문가 수준의 견고한 코드로 발전시키는 경험을 했습니다. 이제 여러분은 AI와 핑퐁 게임을 하듯 대화하며 코드를 다듬는 방법에 익숙해지셨을 겁니다. 이번 세션에서는 여기서 한 걸음 더 나아가, AI가 복잡한 논리에서 길을 잃거나 엉뚱한 대답을 내놓는 현상인 이른바 '환각(Hallucination)'을 원천 차단하는 두 가지 고급 치트키를 배웁니다. 바로 CoT(생각의 사슬)와 Few-shot(소수 예시 학습)입니다.

### 🎯 학습 목표

이 세션이 끝나면 수강생은 다음을 할 수 있어요:

- CoT 기법을 활용하여 AI가 논리적 단계를 밟아 코드를 생성하도록 유도할 수 있습니다.
- Few-shot 기법을 통해 원하는 입력과 출력의 패턴을 AI에게 정확히 학습시킬 수 있습니다.
- 문제의 성격에 따라 두 기법 중 적절한 방법을 선택하여 프롬프트를 고도화할 수 있습니다.

### 선행 세션 환기

바로 앞 세션에서 비밀번호 검사기를 만들 때, 한 번에 완벽한 코드를 얻으려 하지 않고 단계를 나누어 피드백을 주며 코드를 완성했습니다. 이번에 배울 CoT 기법은 그 '단계적 접근'을 AI의 머릿속에서 스스로 하도록 강제하는 방법입니다. 점진적 개선이 여러분과 AI 사이의 대화라면, CoT는 AI 스스로의 내면적인 논리 전개 과정이라고 볼 수 있습니다.

---

## §2. 핵심 개념 (+ 🗣️ 강사 대본 + Mermaid)

### AI 환각 방지 특효약: 생각의 사슬과 예시 학습

AI를 다루다 보면 분명히 논리적으로 맞는 요구를 했는데도, AI가 중간 단계를 훌쩍 건너뛰거나 완전히 엉뚱한 결론을 내리는 경우가 생깁니다. 또는 여러분이 원하는 출력 형식을 아무리 길게 설명해도 AI가 자기 마음대로 다른 형태로 결과를 주기도 하죠. 이럴 때 길게 잔소리하는 것보다 훨씬 효과적인 방법이 바로 CoT와 Few-shot입니다.

🗣️ **강사 대본 (Instructor Script)**:

> 여러분, 수학 시험을 보는 상황을 떠올려 볼까요? 선생님이 칠판에 아주 복잡한 미적분 방정식을 적어놓고 "답만 쓰세요"라고 지시합니다. 학생들은 머릿속으로만 어림짐작해서 답을 찍어냅니다. 당연히 반 전체의 오답률이 엄청나게 높겠죠.
> 
> 그런데 이번에는 선생님이 조건을 바꿉니다. "풀이 과정을 1단계부터 4단계까지 차근차근 적고, 맨 마지막 줄에만 답을 쓰세요." 그러면 학생들은 1단계 식 세우기, 2단계 변수 치환, 3단계 계산, 4단계 검산까지 손으로 적어가면서 스스로 논리를 점검하게 됩니다. 정답률이 어떻게 될까요? 극적으로 올라갈 겁니다.
> 
> 이것이 바로 첫 번째 기법인 CoT, 즉 '생각의 사슬(Chain of Thought)'입니다. AI에게도 "답만 덜렁 내놓지 말고, 네가 어떤 추론 과정을 거쳤는지 단계별로 보여줘"라고 요청하는 겁니다. "Let's think step by step"이라는 마법의 문장 하나, 혹은 1단계, 2단계 목차를 잡아주는 것만으로도 AI는 스스로의 논리적 오류를 잡아내면서 훨씬 정확한 코드를 짜냅니다.
> 
> 두 번째 기법인 Few-shot은 훨씬 더 직관적이에요. 여러분이 외국인 친구에게 한국식 인사법을 가르친다고 가정해 봅시다. 말로 "허리를 45도 숙이고 눈은 바닥을 보면서..."라고 백 번 설명하는 게 빠를까요, 아니면 여러분이 직접 인사하는 동작을 두세 번 보여주는 게 빠를까요? 당연히 보여주는 쪽이 한 번에 이해시킬 수 있습니다.
> 
> AI도 똑같습니다. 원하는 입력과 출력의 예시 쌍을 2~3개만 프롬프트에 직접 포함시켜 보여주세요. "사과를 넣으면 apple이 나오고, 바나나를 넣으면 banana가 나온다. 자, 그럼 포도를 넣으면?" 이렇게 예시를 주면, AI는 그 패턴을 귀신같이 파악해서 "grape"라고 완벽하게 대답합니다. 길게 설명할 필요 없이 패턴을 눈으로 보여주는 것, 이것이 Few-shot입니다.

### Mermaid 다이어그램

```mermaid
flowchart TD
    subgraph Zero-shot
        A[복잡한 문제 입력] --> B[AI가 직관적으로 답 도출]
        B --> C[오류 발생 확률 높음]
    end

    subgraph CoT "CoT (생각의 사슬)"
        D[복잡한 문제 + '단계별로 생각해' 입력] --> E[1단계 논리 전개]
        E --> F[2단계 중간 계산]
        F --> G[3단계 최종 결론]
        G --> H[정확도 극대화]
    end

    subgraph Fewshot "Few-shot (소수 예시 학습)"
        I[입력/출력 패턴 예시 2~3개 제공] --> J[AI가 패턴 규칙 스스로 파악]
        J --> K[새로운 입력]
        K --> L[의도한 형식과 정확한 답안 출력]
    end
```

이 다이어그램은 프롬프트 기법에 따른 AI의 사고 과정을 비교해서 보여줍니다. 일반적인 Zero-shot 방식에서는 AI가 결론으로 직행하다가 실수하기 쉽습니다. 반면 CoT는 사고의 징검다리를 놓아주고, Few-shot은 정답의 모양새를 미리 각인시켜 줍니다. 두 기법 모두 AI가 길을 잃지 않게 만들어주는 아주 튼튼한 가드레일 역할을 합니다.

---

## §3. 상세 내용

### Why — 왜 이 세션이 필요한가?

초보자들이 AI 코딩을 하다가 가장 크게 좌절하는 순간은 AI가 엉뚱한 코드를 내놓을 때입니다. 분명히 제대로 지시했다고 생각했는데, AI가 출력한 코드가 작동하지 않거나 요구사항을 무시하는 일이 발생하죠. 이때 보통 프롬프트를 점점 더 길고 복잡하게 쓰려는 함정에 빠집니다. 하지만 말이 길어질수록 AI는 더 헷갈립니다. 길게 설명하는 대신 구조적으로 사고하게 만들거나, 백 마디 말 대신 하나의 확실한 예시를 보여주는 기술이 필요합니다. 환각을 줄이고 통제력을 높이는 가장 확실한 두 가지 무기를 장착하기 위해 이 시간이 필요합니다.

### What — 이 세션에서 다루는 것은 무엇인가?

이 세션은 두 가지 핵심 고급 기법을 다룹니다.

첫째, 생각의 사슬(Chain of Thought)입니다. 복잡한 문제를 풀 때 AI에게 중간 추론 과정을 명시적으로 요구하는 기법입니다. 논리적 추론 능력이 극적으로 향상되며 수학적 계산, 조건이 복잡한 비즈니스 로직, 알고리즘 설계에서 매우 탁월한 효과를 발휘합니다.

둘째, 소수 예시 학습(Few-shot Prompting)입니다. 예시 없이 바로 요청하는 것을 Zero-shot이라고 부르는데, 이와 대비되는 개념입니다. 원하는 입력과 출력의 예시 쌍을 1~3개 정도 프롬프트 안에 직접 포함시켜 AI에게 패턴을 암묵적으로 학습시키는 방법입니다. 데이터의 형태를 변환하거나 출력 포맷을 엄격하게 유지해야 할 때 필수적인 기법입니다.

### How — 구체적으로 어떻게 진행하는가?

이론을 길게 설명하는 대신, Antigravity 환경에서 두 가지 기법이 어떻게 동작하는지 직접 눈으로 확인하는 실습 위주로 진행합니다. 피보나치 수열이라는 알고리즘 문제를 통해 CoT가 어떻게 논리적 비약을 막아주는지 관찰하고, 데이터 포맷 변환 문제를 통해 Few-shot이 어떻게 AI를 길들이는지 체험합니다.

---

## §4. 실습 가이드 (+ 🎙️ 실습 대본)

### 실습 목표

수강생들이 직접 Antigravity에 CoT와 Few-shot 프롬프트를 입력해 보고, AI가 사고의 과정을 출력하거나 제공된 패턴을 정확히 따라 하는 것을 확인합니다. 이를 통해 복잡한 문제를 만났을 때 당황하지 않고 프롬프트 기법을 적용할 수 있는 자신감을 기릅니다.

🎙️ **실습 가이드 대본 (Lab Guide)**:

> 자, 이제 화면의 Antigravity를 열고 직접 실험해 봅시다. 먼저 CoT 기법을 써볼 거예요. 파이썬으로 피보나치 수열을 만드는 코드를 짜달라고 할 건데, 그냥 짜달라고 하지 않고 단계별 지시를 내려볼 겁니다.
> 
> 교안 §5에 있는 첫 번째 예시 코드를 그대로 복사해서 붙여넣기 해보세요. 프롬프트 내용을 자세히 보면 1단계부터 4단계까지 AI가 밟아야 할 사고의 순서가 적혀 있습니다. 엔터를 치고 AI의 답변을 지켜보세요. AI가 바로 코드를 툭 던지는 게 아니라, 자기가 수학적 정의를 어떻게 이해했는지 먼저 말하고 알고리즘 설계를 이야기한 다음에야 코드를 보여줄 겁니다. 이렇게 논리를 먼저 점검하게 만들면 엣지 케이스에서 버그가 날 확률이 뚝 떨어집니다.
> 
> 이번에는 Few-shot 기법을 실습해 볼게요. §5의 두 번째 예시를 복사해서 새 대화창에 넣어주세요. 여기서는 AI에게 "숫자를 계산해서 문자열로 예쁘게 포맷팅해 줘"라고 길게 설명하는 대신, 그냥 입력과 출력 예시 두 개만 툭 던져줬습니다. 그리고 마지막에 우리가 진짜로 풀고 싶은 문제를 줬죠.
> 
> 결과가 어떻게 나왔나요? 네, AI가 "리스트 합계: 45, 평균: 15.0"이라고 우리가 예시에서 보여준 패턴과 토씨 하나 틀리지 않고 똑같은 형식으로 답을 내놓았습니다. 복잡한 출력 형식을 요구할 때는 이렇게 예시를 보여주는 것이 가장 강력한 지시입니다.

### 단계별 지시

| 단계 | 소요 시간 | 강사 지시사항 | 학습자 액션 | 예상 결과 |
|------|----------|--------------|------------|----------|
| 1 | 3분 | CoT와 Few-shot 개념 비유로 설명 | 경청 | 두 기법의 차이점 및 용도 이해 |
| 2 | 5분 | "Antigravity에 CoT 프롬프트 입력해 보세요" | 예시 복사 후 실행 | AI의 단계별 추론 과정 출력 확인 |
| 3 | 5분 | "새 대화창에 Few-shot 프롬프트 입력해 보세요" | 예시 복사 후 실행 | 패턴을 정확히 모방한 결과물 확인 |
| 4 | 2분 | 결과물 비교 및 체크포인트 질문 | 결과 관찰 및 답변 | 기법의 효과 실감 |

### 트러블슈팅 FAQ

| Q | A |
|---|---|
| 예시를 몇 개나 줘야 하나요? 많이 줄수록 좋은가요? | 보통 1개(One-shot)에서 3개 정도면 충분합니다. 너무 많은 예시를 주면 프롬프트가 길어져서 오히려 AI가 핵심을 놓칠 수 있어요. 패턴이 명확하다면 2개로도 완벽하게 작동합니다. |
| CoT를 썼는데도 AI가 단계를 건너뛰어요. | 그럴 때는 프롬프트 맨 끝에 "반드시 1단계부터 순서대로 출력 결과를 보여준 후에 다음 단계로 넘어가세요"라고 강력한 제약 조건을 한 줄 추가해 주면 해결됩니다. |
| 두 기법을 섞어서 써도 되나요? | 네, 물론입니다. 복잡한 계산식의 출력을 특정한 형태로 받아야 할 때는, "단계별로 생각해서 풀어줘"라고 CoT를 지시한 후 맨 마지막에 "최종 답은 다음 예시처럼 출력해"라며 Few-shot을 결합하면 최고의 결과가 나옵니다. |

> ✅ **체크포인트**: 논리적으로 복잡한 알고리즘을 짤 때는 어떤 기법이 유리할까요? 정해진 양식의 보고서 텍스트를 뽑아낼 때는 어떤 기법이 유리할까요?

---


### 🎓 강사 노트 (Instructor Support)

- ⏱️ **타이밍**: 13:00 (20분, code)
- 🎯 **핵심 활동**: 생각의 사슬, 예시 제공 기법
- ⚠️ **강사 주의사항**: 난이도 높음. 이해 못해도 OK 전달

## §5. 코드 및 명령어 모음

### CoT (생각의 사슬) 프롬프트 실습 예시

이 프롬프트를 Antigravity에 입력하여 AI가 논리를 전개하는 과정을 관찰합니다.

```python
# 프롬프트 입력창에 복사해서 붙여넣으세요
"""
피보나치 수열의 n번째 값을 반환하는 파이썬 함수를 작성해 주세요.
단, 다음 단계를 따라 논리적으로 접근해 주세요:

1단계: 피보나치 수열의 수학적 정의를 먼저 정리하세요.
2단계: 반복문 기반의 알고리즘을 설계하세요.
3단계: 설계를 바탕으로 파이썬 코드를 작성하세요.
4단계: n이 0이나 음수일 때의 예외 처리를 추가하세요.
"""
```

### Few-shot (소수 예시 학습) 프롬프트 실습 예시

데이터 변환 패턴을 학습시키기 위해 아래 프롬프트를 새 대화창에 입력합니다.

```python
# 프롬프트 입력창에 복사해서 붙여넣으세요
"""
다음 패턴을 학습한 후, 마지막 입력에 대해 동일한 형식으로 답해 주세요.

예시 1)
입력: [1, 2, 3]
출력: "리스트 합계: 6, 평균: 2.0"

예시 2)
입력: [10, 20, 30, 40]
출력: "리스트 합계: 100, 평균: 25.0"

문제)
입력: [5, 15, 25]
출력:
"""
```

---

## §6. 요약

### 핵심 학습 포인트

이번 세션에서는 AI의 지능을 100% 끌어올리고 환각을 방지하는 두 가지 핵심 기술을 익혔습니다. 첫째, CoT(Chain of Thought)입니다. AI에게 답을 재촉하지 않고 논리적인 사고 과정을 단계별로 요구함으로써 오류를 줄이고 복잡한 알고리즘을 성공적으로 설계할 수 있습니다. 둘째, Few-shot 프롬프팅입니다. 원하는 결과의 형태를 길게 묘사하는 대신 2~3개의 명확한 예시를 제시하여 AI가 패턴을 직관적으로 모방하게 만드는 가장 확실한 통제 방법입니다.

### 다음 세션 예고

지금까지 오전 세션 내내 우리는 프롬프트 엔지니어링의 핵심을 모두 배웠습니다. PTCF 구조를 잡고, 필수 명세를 채우고, 점진적으로 코드를 개선하며, CoT와 Few-shot으로 지능을 끌어올렸죠. 지금까지는 AI와 "어떻게" 소통할 것인가에 대한 기술이었습니다. 이제 점심식사 후 오후 시간에는 한 차원 더 높은 곳으로 올라갑니다. 바로 AI에게 "무엇을" 시킬 것인가를 결정하는 요구사항(Requirements)과 명세서 기획의 세계로 진입합니다.

### 브릿지 노트

> "여러분, 이제 우리는 AI라는 아주 똑똑한, 하지만 가끔 엉뚱한 짓을 하는 조수를 완벽하게 다루는 조종법을 익혔습니다. 프롬프트 기술은 다 배웠어요. 그런데 생각해 보세요. 아무리 조종을 잘해도, 우리가 어디로 가야 할지 모르면 의미가 없겠죠? 오후부터는 AI 시대에 코딩보다 훨씬 더 중요해진 능력, 즉 '내가 진짜로 원하는 게 무엇인지 정의하는 방법'에 대해 깊이 파헤쳐 보겠습니다. 식사 맛있게 하시고 오후에 뵙겠습니다."

---

## §7. 참고 자료

### 3-Source 출처

- **Source A (로컬 참고자료)**: `3 프롤프트 엔지니어링.pdf` — §3.5 CoT 및 §3.6 Few-shot 프롬프팅 이론 원전. 프롬프트 작성의 기본 틀과 두 기법의 정의를 참고했습니다.
- **Source B (NotebookLM)**: NotebookLM 분석 리포트 — AI 환각 방지와 추론 성능 극대화 전략 분석 내용 반영. 복잡한 논리 구조 해결을 위한 특효약으로서 두 기법의 가치를 추출했습니다.
- **Source C (Deep Research)**: Deep Research 보고서 — 코드 생성 맥락에서의 CoT/Few-shot 적용 사례 보강. 에이전트 주도 개발 트렌드에서 두 기법이 어떻게 활용되는지 배경 지식을 참고했습니다.

### 강사 노트

> 💡 **강사 노트**: 이 세션은 Day 2 오전의 마지막 기술 파트입니다. CoT와 Few-shot이라는 전문 용어가 비전공자에게 낯설 수 있으므로, 수학 시험 비유와 외국인 친구 인사법 비유를 충분히 살려서 설명해 주시기 바랍니다. 실습 시 수강생들이 직접 결과를 확인하고 감탄하는 포인트를 이끌어내는 것이 중요합니다. 이 세션이 끝나면 프롬프트 엔지니어링(How) 파트가 마무리되고 기획(What) 파트로 넘어간다는 점을 명확히 짚어주세요.

---

## ✅ 세션 완료 체크리스트 (강사용)

- [ ] §1~§7 모든 섹션이 빠짐없이 충실하게 작성되었는가?
- [ ] CoT와 Few-shot의 핵심 개념을 일상적인 비유를 들어 쉽게 설명했는가?
- [ ] 수강생이 직접 실행해 볼 수 있는 두 가지 실습 코드가 포함되었는가?
- [ ] 환각 방지라는 이 세션의 가장 큰 목적이 잘 드러났는가?
- [ ] 3-Source 팩트 패킷의 내용이 적절히 반영되었는가?

---

*작성 일시: 2026-02-25*  
*작성 에이전트: A4B_Session_Writer*  
*교안 구조: 7섹션 (A0 팀 공통 표준)*