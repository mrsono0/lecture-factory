{
  "$schema": "https://raw.githubusercontent.com/code-yeongyu/oh-my-opencode/master/assets/oh-my-opencode.schema.json",
  // ============================================================
  // Lecture Factory - Project-Specific Model Configuration
  // ============================================================
  // This file overrides ~/.config/opencode/oh-my-opencode.json
  // for the _lecture-factory project only.
  //
  // Principle: Models are inherited from global config.
  //            Only prompt_append (domain context injection)
  //            and select model overrides are project-specific.
  // ============================================================
  // === Agent-Level Model Overrides ===
  "agents": {
    // Main Orchestrator: Multi-pipeline coordination (7 pipelines)
    // Kimi K2.5 ‚Äî Agent Swarm (100 sub-agents), tool-use #1, 256K context, ~30x cost reduction
    "sisyphus": {
      "model": "opencode/kimi-k2.5"
    },
    // Codebase Explorer: Pattern search within lecture materials
    // Fast & cheap - just grep/read operations
    "explore": {
      "model": "anthropic/claude-sonnet-4-6"
    },
    // Reference Researcher: Technical docs, library lookups
    // Anthropic Sonnet 4.6 ‚Äî superior document parsing & structured output quality
    "librarian": {
      "model": "anthropic/claude-sonnet-4-6"
    },
    // Architecture Consultant: Curriculum/material structure review
    // Reasoning-specialized model for strategic decisions
    "oracle": {
      "model": "opencode/gpt-5.2",
      "variant": "high"
    },
    // Deep Executor: Complex autonomous goal-oriented tasks
    // Reasoning-specialized for multi-step implementation
    "hephaestus": {
      "model": "opencode/gpt-5.3-codex"
    }
  },
  // === Category-Level Model + Context Injection ===
  // Categories are used via task(category="...", prompt="...")
  // prompt_append injects Lecture Factory domain context
  "categories": {
    // Pipeline 02 (Material Writing): Long-form lecture scripts
    // Requires highest quality for instructor scripts + learner narratives
    "deep": {
      "model": "anthropic/claude-opus-4-6",
      "variant": "max",
      "prompt_append": "You are writing Korean lecture materials for the Lecture Factory system. Follow these conventions:\n- Use friendly spoken Korean tone (~haeyo, ~imnida), never formal written style (~handa)\n- Include instructor scripts with the emoji prefix: '\ud83d\udde3\ufe0f \uac15\uc0ac \ub300\ubcf8 (Instructor Script):'\n- Include lab guide scripts with: '\ud83c\udf99\ufe0f \uc2e4\uc2b5 \uac00\uc774\ub4dc \ub300\ubcf8 (Lab Guide):'\n- Use rich analogies and narrative tone ('AI \uc2dc\ub300\uc758 \uc11c\uc0ac')\n- Follow Why -> What -> How structure for every new concept\n- All outputs must be in Korean (except technical terms)"
    },
    // Pipeline 03 (Slide Generation) & 06 (NanoBanana): Visual planning + AI image generation
    // Gemini 3.1 Pro ‚Äî latest model, 1M context, enhanced visual reasoning
    "visual-engineering": {
      "model": "google/antigravity-gemini-3.1-pro",
      "variant": "high",
      "prompt_append": "You are creating slide storyboards for the Lecture Factory system. Follow these conventions:\n- Use Bento Grid layout with Sketch Note (ink-pen) visual style\n- One core concept per slide, max 2 new terms per slide\n- Instructor notes go in Speaker Notes area\n- Include T-BRIDGE transition slides between major sections\n- Checkpoint slides every 5-7 slides\n- All slide copy in Korean, friendly tone"
    },
    // Pipeline 04/05/07 (PPTX Conversion / Manus): Mechanical transformation
    // Fast & cheap ‚Äî no creativity needed, just accurate conversion
    // NOTE: Requires Anthropic provider auth ‚Äî run /connect in OpenCode TUI
    "quick": {
      "model": "anthropic/claude-haiku-4-5"
    },
    // Pipeline 06 (Slide Prompt Generation): Precise prompt crafting
    // 1M context window essential ‚Äî embeds FULL lecture material in each prompt
    "writing": {
      "model": "google/antigravity-gemini-3.1-pro",
      "variant": "high",
      "prompt_append": "You are generating slide creation prompts for the Lecture Factory system (Pipeline 06). Follow these conventions:\n- Include the FULL lecture material markdown in section 6 (\uad50\uc548 \uc6d0\ubb38)\n- Follow the P0/P2 agent specifications for prompt structure\n- Output format must be compatible with Manus AI (Nano Banana Pro)\n- Each prompt file covers one session (AM/PM)\n- All outputs in Korean"
    },
    // Curriculum Design: Complex learning architecture
    // Reasoning-specialized for dependency mapping and scaffolding
    "ultrabrain": {
      "model": "opencode/gpt-5.3-codex",
      "variant": "xhigh"
    },
    // Reasoning High: targeted analysis and synthesis tasks
    "reasoning-high": {
      "model": "openai/gpt-5.3-codex",
      "variant": "high"
    },
    // Reasoning Xhigh: maximum-depth reasoning for complex planning
    "reasoning-xhigh": {
      "model": "openai/gpt-5.3-codex",
      "variant": "xhigh"
    },
    // NEW: Micro Session Chunking - 15~25min session design
    // Gemini 3.1 Pro ‚Äî 1M context for chunk_type tagging and dependency mapping
    "curriculum-chunking": {
      "model": "google/antigravity-gemini-3.1-pro",
      "variant": "high",
      "prompt_append": "You are designing MICRO-SESSIONS (15-25min chunks) for curriculum planning. CRITICAL RULES:\n1. Each session MUST target exactly ONE learning objective\n2. Time: 15-25min (3,000-4,500 chars when written)\n3. Output estimated_chars (3000|4000|4500) and complexity tags\n4. Define clear prerequisites and dependencies\n5. Specify chunk_type: narrative|code|diagram|lab\n6. Include üó£Ô∏è instructor script outline (1,500-2,000 chars)\n7. Include üéôÔ∏è lab guide if applicable\n8. Use 'AI ÏãúÎåÄÏùò ÏÑúÏÇ¨' tone for analogies\n9. All outputs in Korean"
    },
    // NEW: Micro Session Writing - Individual session material (3,000-4,500 chars)
    // Gemini 3.1 Pro ‚Äî 1M context, optimized for long-form continuous prose
    "micro-writing": {
      "model": "google/antigravity-gemini-3.1-pro",
      "variant": "high",
      "prompt_append": "You are writing a SINGLE micro-session (15-25min) lecture material. CRITICAL RULES:\n1. Output MUST be 3,000-4,500 characters (Korean, including spaces)\n2. NEVER use bullet points, lists, or tables in main narrative\n3. Use continuous prose style (novel/essay-like paragraphs only)\n4. Tone: Friendly spoken Korean (~haeyo, ~imnida), NEVER formal (~handa)\n5. Structure: Hook (previous recap) ‚Üí Analogy (detailed situational drama) ‚Üí Concept (line-by-line explanation) ‚Üí Code/Example (if applicable) ‚Üí Checkpoint Q&A\n6. Include ONLY ONE core concept per session\n7. All scripts must be verbatim-readable by instructors\n8. Use üó£Ô∏è for instructor scripts (1,500-2,000 chars), üéôÔ∏è for lab guides\n9. Include detailed analogies with 'AI ÏãúÎåÄÏùò ÏÑúÏÇ¨' tone\n10. All outputs must be in Korean (except technical terms)"
    },
    // Creative Tasks: Differentiation strategies, narrative design
    // Gemini 3.1 Pro ‚Äî latest model for creative/artistic content
    "artistry": {
      "model": "google/antigravity-gemini-3.1-pro",
      "variant": "high"
    },
    // Research Tasks: Trend analysis, source-based research, deep web search
    // Gemini 3.1 Pro ‚Äî 1M context for large-scale research synthesis, native tool-use for bash execution
    "research": {
      "model": "google/antigravity-gemini-3.1-pro",
      "variant": "high"
    },
    // General High-Effort: Fallback for unclassified complex tasks
    "unspecified-high": {
      "model": "anthropic/claude-opus-4-6",
      "variant": "max"
    },
    // General Low-Effort: Fallback for unclassified simple tasks
    "unspecified-low": {
      "model": "opencode/claude-sonnet-4-6"
    }
  }
}
